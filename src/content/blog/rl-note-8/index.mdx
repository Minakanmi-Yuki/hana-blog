---
title: "RLç¬”è®°ï¼ˆ8ï¼‰ï¼šDQN"
publishDate: 2025-12-17
updatedDate: 2025-12-17
description: "æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å¼€å±±ä¹‹ä½œã€‚è¯¦è§£ DQN å¦‚ä½•åˆ©ç”¨ç¥ç»ç½‘ç»œæ‹Ÿåˆ Q å€¼ï¼Œä»¥åŠä¸¤å¤§æ ¸å¿ƒåˆ›æ–°ï¼šç»éªŒå›æ”¾ä¸ç›®æ ‡ç½‘ç»œã€‚è¿›é˜¶æ¶µç›– Double DQN ä¸ Dueling DQNã€‚"
heroImage: {src : "https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp", color: '#8C8275'}
category: 'daily'
pixivLink: '127192375'
---

## å¼•è¨€ï¼ˆIntroductionï¼‰

åœ¨ä¹‹å‰çš„ Q-Learning ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªçŸ©é˜µï¼ˆQ-Tableï¼‰æ¥è®°å½•æ¯ä¸ªçŠ¶æ€åŠ¨ä½œå¯¹ $(s,a)$ çš„ä»·å€¼ã€‚
è¿™ç§æ–¹æ³•æœ‰ä¸¤ä¸ªè‡´å‘½å±€é™ï¼š
1.  **å†…å­˜é™åˆ¶**ï¼šå¦‚æœçŠ¶æ€ç©ºé—´å¾ˆå¤§ï¼ˆä¾‹å¦‚å›´æ£‹ $10^{170}$ï¼‰ï¼Œè¡¨æ ¼æ ¹æœ¬å­˜ä¸ä¸‹ã€‚è¿™è¢«ç§°ä¸º**ç»´åº¦ç¾éš¾ (Curse of Dimensionality)**ã€‚
2.  **æ³›åŒ–èƒ½åŠ›å·®**ï¼šå¯¹äºæ²¡è§è¿‡çš„çŠ¶æ€ï¼Œè¡¨æ ¼æ— æ³•ç»™å‡ºä¼°è®¡ï¼Œè€Œåœ¨è¿ç»­çŠ¶æ€ç©ºé—´ä¸­ï¼Œå‡ ä¹å¾ˆéš¾é‡åˆ°å®Œå…¨ä¸€æ ·çš„çŠ¶æ€ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥**å‡½æ•°æ‹Ÿåˆ (Function Approximation)**ã€‚**æ·±åº¦Qç½‘ç»œ (Deep Q-Network, DQN)** ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œ $Q_\omega(s, a)$ æ¥è¿‘ä¼¼ $Q^*(s, a)$ï¼Œè¾“å…¥çŠ¶æ€ $s$ï¼Œè¾“å‡ºæ‰€æœ‰ç¦»æ•£åŠ¨ä½œçš„ Q å€¼ã€‚

---

## æ·±åº¦ Q ç½‘ç»œ (DQN)

### æ ¸å¿ƒå®šä¹‰
åœ¨ DQN ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å‚æ•°ä¸º $\omega$ çš„ç¥ç»ç½‘ç»œæ¥æ‹ŸåˆåŠ¨ä½œä»·å€¼å‡½æ•°ã€‚
*   **è¾“å…¥**ï¼šçŠ¶æ€ $s$ï¼ˆä¾‹å¦‚æ¸¸æˆçš„å±å¹•åƒç´ ï¼‰ã€‚
*   **è¾“å‡º**ï¼šæ¯ä¸ªåŠ¨ä½œ $a \in \mathcal{A}$ å¯¹åº”çš„ä»·å€¼ $Q(s,a)$ã€‚

### æŸå¤±å‡½æ•°
ç±»ä¼¼äº Q-Learningï¼Œæˆ‘ä»¬å¸Œæœ›ç¥ç»ç½‘ç»œçš„è¾“å‡ºé€¼è¿‘ TD Targetã€‚
å¯¹äºä¸€æ¡æ•°æ® $(s_i, a_i, r_i, s_i^\prime)$ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–å‡æ–¹è¯¯å·®ï¼š

$$
J(\omega)=\frac{1}{2N}\sum_{i=1}^{N}\left[ \underbrace{Q_\omega(s_i,a_i)}_{\text{é¢„æµ‹å€¼}} - \underbrace{\left(r_i+\gamma \max_{a^\prime}Q_\omega(s_i^\prime,a^\prime)\right)}_{\text{TD Target}} \right]^2
$$

ç„¶è€Œï¼Œç›´æ¥è¿™æ ·è®­ç»ƒæ˜¯ä¸ç¨³å®šçš„ã€‚DQN å¼•å…¥äº†ä¸¤å¤§â€œæ³•å®â€æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

---

## åˆ›æ–°ä¸€ï¼šç»éªŒå›æ”¾ (Experience Replay)

åœ¨ä¸€èˆ¬çš„ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å‡è®¾è®­ç»ƒæ•°æ®æ˜¯**ç‹¬ç«‹åŒåˆ†å¸ƒ (i.i.d)** çš„ã€‚ä½†åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ™ºèƒ½ä½“é‡‡é›†çš„æ•°æ®æ˜¯åºåˆ—ç›¸å…³çš„ï¼ˆç°åœ¨çš„çŠ¶æ€ä¾èµ–äºä¸Šä¸€ç§’çš„çŠ¶æ€ï¼‰ã€‚

**åšæ³•**ï¼š
ç»´æŠ¤ä¸€ä¸ª**å›æ”¾ç¼“å†²åŒº (Replay Buffer)** $\mathcal{R}$ã€‚
1.  æ™ºèƒ½ä½“ä¸ç¯å¢ƒäº¤äº’ï¼Œå°†äº§ç”Ÿçš„æ•°æ® $(s_t, a_t, r_t, s_{t+1})$ å­˜å…¥ç¼“å†²åŒºã€‚
2.  è®­ç»ƒæ—¶ï¼Œä»ç¼“å†²åŒºä¸­**éšæœºé‡‡æ ·**ä¸€ä¸ªæ‰¹æ¬¡ (Batch) çš„æ•°æ®è¿›è¡Œæ¢¯åº¦ä¸‹é™ã€‚

**ä½œç”¨**ï¼š
1.  **æ‰“ç ´ç›¸å…³æ€§**ï¼šéšæœºé‡‡æ ·æ¶ˆé™¤äº†æ•°æ®ä¹‹é—´çš„æ—¶é—´ç›¸å…³æ€§ï¼Œæ»¡è¶³ç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾ï¼Œç¨³å®šç½‘ç»œè®­ç»ƒã€‚
2.  **æé«˜æ ·æœ¬æ•ˆç‡**ï¼šä¸€æ¡ç»éªŒæ•°æ®å¯ä»¥è¢«å¤šæ¬¡é‡‡æ ·åˆ©ç”¨ï¼Œè€Œä¸æ˜¯ç”¨å®Œå³å¼ƒã€‚

---

## åˆ›æ–°äºŒï¼šç›®æ ‡ç½‘ç»œ (Target Network)

åœ¨åŸç‰ˆ Q-Learning ä¸­ï¼ŒTD Target çš„è®¡ç®—ä¹Ÿä¾èµ–äºå½“å‰ç½‘ç»œå‚æ•° $\omega$ï¼š
$$
y_i = r_i + \gamma \max_{a'} Q_\omega(s'_i, a')
$$
è¿™å°±å¥½æ¯”â€œåœ¨å°„ç®­çš„åŒæ—¶ï¼Œé¶å­ä¹Ÿåœ¨åŠ¨â€ã€‚æ›´æ–° $\omega$ ä¼šåŒæ—¶æ”¹å˜é¢„æµ‹å€¼å’Œç›®æ ‡å€¼ï¼Œå®¹æ˜“å¯¼è‡´éœ‡è¡å‘æ•£ã€‚

**åšæ³•**ï¼š
å¼•å…¥ä¸€ä¸ªç»“æ„ç›¸åŒä½†å‚æ•°ç‹¬ç«‹çš„**ç›®æ ‡ç½‘ç»œ (Target Network)**ï¼Œå‚æ•°è®°ä¸º $\omega^-$ã€‚
è®¡ç®—ç›®æ ‡å€¼æ—¶ä½¿ç”¨ $\omega^-$ï¼Œæ›´æ–°ç½‘ç»œæ—¶ä¼˜åŒ– $\omega$ã€‚

$$
y_i = r_i + \gamma \max_{a'} Q_{\omega^-}(s'_i, a')
$$

**æ›´æ–°è§„åˆ™**ï¼š
*   **è®­ç»ƒç½‘ç»œ $\omega$**ï¼šæ¯ä¸ª step éƒ½è¿›è¡Œæ¢¯åº¦ä¸‹é™æ›´æ–°ã€‚
*   **ç›®æ ‡ç½‘ç»œ $\omega^-$**ï¼šæ¯éš” $C$ æ­¥ï¼ˆä¾‹å¦‚ 1000 æ­¥ï¼‰ï¼Œå°† $\omega$ çš„å€¼å¤åˆ¶ç»™ $\omega^-$ ($\omega^- \leftarrow \omega$)ã€‚

> **ğŸ’¡ ç›´è§‰**ï¼šå›ºå®šä½é¶å­ä¸€ä¼šå„¿ï¼Œè®©å°„æ‰‹ï¼ˆè®­ç»ƒç½‘ç»œï¼‰å®‰å¿ƒç„å‡†ï¼Œç­‰å°„æ‰‹ç»ƒå¥½äº†ï¼Œå†æŠŠé¶å­æŒªåˆ°æ–°çš„ä½ç½®ã€‚

---

## DQN ç®—æ³•ä¼ªä»£ç 

$$
\begin{aligned}
& \bullet \; \text{Initialize main network } Q_\omega \text{ and target network } Q_{\omega^-} \text{ with weights } \omega \\
& \bullet \; \text{Initialize replay buffer } \mathcal{R} \\
& \bullet \; \textbf{For } \text{episode } e = 1 \to E \textbf{ do}: \\
& \bullet \qquad \text{Initialize state } s \\
& \bullet \qquad \textbf{For } \text{step } t = 1 \to T \textbf{ do}: \\
& \bullet \qquad \qquad \text{Select action } a \text{ using } \epsilon\text{-greedy based on } Q_\omega(s) \\
& \bullet \qquad \qquad \text{Execute } a, \text{ observe } r, s' \\
& \bullet \qquad \qquad \text{Store transition } (s, a, r, s') \text{ in } \mathcal{R} \\
& \bullet \qquad \qquad \textbf{If } |\mathcal{R}| > \text{batch\_size}: \\
& \bullet \qquad \qquad \qquad \text{Sample batch } \{(s_i, a_i, r_i, s'_i)\}_{i=1}^N \text{ from } \mathcal{R} \\
& \bullet \qquad \qquad \qquad \text{Calculate targets: } y_i = r_i + \gamma \max_{a'} Q_{\omega^-}(s'_i, a') \\
& \bullet \qquad \qquad \qquad \text{Update } \omega \text{ by minimizing } \frac{1}{N}\sum (Q_\omega(s_i, a_i) - y_i)^2 \\
& \bullet \qquad \qquad \qquad \textbf{Every } C \text{ steps: } \omega^- \leftarrow \omega \\
& \bullet \qquad \qquad s \leftarrow s' \\
& \bullet \qquad \textbf{End For} \\
& \bullet \; \textbf{End For}
\end{aligned}
$$

---

## è¿›é˜¶ 1ï¼šDouble DQN

### é—®é¢˜ï¼šè¿‡é«˜ä¼°è®¡ (Overestimation)
DQN åœ¨è®¡ç®—ç›®æ ‡å€¼æ—¶ä½¿ç”¨äº† $\max$ æ“ä½œï¼š$y_i = r + \gamma \max_{a'} Q(s', a')$ã€‚
ç”±äºç¥ç»ç½‘ç»œæœ¬èº«å­˜åœ¨ä¼°è®¡è¯¯å·®ï¼Œ$\max$ æ“ä½œå€¾å‘äºé€‰æ‹©é‚£äº›è¢«**é«˜ä¼°**çš„å€¼ã€‚è¿™ç§**æœ€å¤§åŒ–åå·® (Maximization Bias)** ä¼šå¯¼è‡´ Q å€¼æ™®éåå¤§ï¼Œå½±å“ç­–ç•¥å­¦ä¹ ã€‚

### è§£å†³æ–¹æ¡ˆ
**è§£è€¦é€‰æ‹©ä¸è¯„ä¼°**ã€‚
*   **é€‰æ‹©åŠ¨ä½œ**ï¼šä½¿ç”¨å½“å‰ç½‘ç»œ $Q_\omega$ æ¥å†³å®šå“ªä¸ªåŠ¨ä½œæœ€å¥½ï¼ˆå³ argmaxï¼‰ã€‚
*   **è¯„ä¼°ä»·å€¼**ï¼šä½¿ç”¨ç›®æ ‡ç½‘ç»œ $Q_{\omega^-}$ æ¥è®¡ç®—é‚£ä¸ªåŠ¨ä½œçš„ä»·å€¼ã€‚

**Double DQN ç›®æ ‡å…¬å¼**ï¼š
$$
y_i = r_i + \gamma Q_{\omega^-}(s'_i, \underset{a'}{\operatorname{argmax}} Q_\omega(s'_i, a'))
$$

---

## è¿›é˜¶ 2ï¼šDueling DQN

### æ ¸å¿ƒæ€æƒ³
åœ¨å¾ˆå¤šçŠ¶æ€ä¸‹ï¼Œ**çŠ¶æ€æœ¬èº«çš„ä»·å€¼**æ¯”**é€‰æ‹©ä»€ä¹ˆåŠ¨ä½œ**æ›´é‡è¦ã€‚
ä¾‹å¦‚ï¼šåœ¨èµ›è½¦æ¸¸æˆä¸­ï¼Œå¦‚æœå‰é¢æ˜¯æ­»èƒ¡åŒï¼ˆçŠ¶æ€å·®ï¼‰ï¼Œæ— è®ºä½ å‘å·¦è½¬è¿˜æ˜¯å‘å³è½¬ï¼ˆåŠ¨ä½œï¼‰ï¼Œä»·å€¼éƒ½å¾ˆä½ã€‚
Dueling DQN æ”¹å˜äº†ç½‘ç»œç»“æ„ï¼Œå°† Q å€¼åˆ†è§£ä¸ºä¸¤éƒ¨åˆ†ï¼š
1.  **çŠ¶æ€ä»·å€¼å‡½æ•° (Value Function)** $V(s)$ï¼šä»…ä¸çŠ¶æ€æœ‰å…³ã€‚
2.  **ä¼˜åŠ¿å‡½æ•° (Advantage Function)** $A(s,a)$ï¼šä¸åŠ¨ä½œæœ‰å…³ï¼Œè¡¨ç¤ºåŠ¨ä½œ $a$ ç›¸æ¯”å¹³å‡æƒ…å†µå¥½å¤šå°‘ã€‚

$$
Q(s, a) = V(s) + A(s, a)
$$

### å¯è¾¨è¯†æ€§é—®é¢˜ (Identifiability)
å¦‚æœç›´æ¥ç”¨ $V+A$ï¼Œç½‘ç»œä¼šå‡ºç°å”¯ä¸€æ€§é—®é¢˜ï¼ˆ$V$ åŠ  10ï¼Œ$A$ å‡ 10ï¼Œæ€»å’Œ $Q$ ä¸å˜ï¼‰ã€‚ä¸ºäº†è®© $V$ å’Œ $A$ èƒ½è¢«å”¯ä¸€ç¡®å®šï¼Œæˆ‘ä»¬éœ€è¦å¼ºè¡Œçº¦æŸ $A$ çš„æŸç§æ€§è´¨ã€‚

**èšåˆå…¬å¼ (Aggregation)**ï¼š
é€šå¸¸è®©ä¼˜åŠ¿å‡½æ•° $A$ å¯¹äºæŸä¸ªçŠ¶æ€çš„å‡å€¼ä¸º 0ï¼Œæˆ–è€…æœ€å¤§å€¼ä¸º 0ã€‚
$$
Q(s,a;\theta,\alpha,\beta)=V(s;\theta,\beta) + \left( A(s,a;\theta,\alpha) - \frac{1}{|\mathcal{A}|}\sum_{a^\prime}A(s,a^\prime;\theta,\alpha) \right)
$$
æˆ–è€…ï¼š
$$
Q(s,a;\theta,\alpha,\beta)=V(s;\theta,\beta) + \left( A(s,a;\theta,\alpha) - \max_{a^\prime}A(s,a^\prime;\theta,\alpha) \right)
$$

**ä¼˜ç‚¹**ï¼š
*   åœ¨åŠ¨ä½œå¯¹ç¯å¢ƒå½±å“ä¸å¤§çš„çŠ¶æ€ä¸‹ï¼Œèƒ½æ›´å¿«åœ°å­¦ä¹ çŠ¶æ€ä»·å€¼ $V$ã€‚
*   æå¤§åœ°æé«˜äº†è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ã€‚